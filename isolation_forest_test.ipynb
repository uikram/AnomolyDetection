{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import math\n",
    "import os\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'all_combined_EMA2324M10139.csv'\n",
    "df = pd.read_csv('data/'+filename)\n",
    "df = df.dropna(subset='cycle_time')\n",
    "# df = df.rename(columns={'CT': 'cycle_time', 'Shot Time': 'shot_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset='cycle_time')\n",
    "df = df[['shot_time','cycle_time']]\n",
    "data = ['cycle_time']\n",
    "df['cycle_time'] = df['cycle_time'].apply(math.floor)\n",
    "if_model = IsolationForest(contamination='auto',n_estimators=300,random_state=42,warm_start=True)\n",
    "if_model.fit(df[data])\n",
    "df['anomoly_score'] = if_model.decision_function(df[data])\n",
    "df['anomoly_score_inverse']=if_model.score_samples(df[data])\n",
    "# df['anomoly_score'] = df['anomoly_score']+1\n",
    "df['anomoly_score_inverse'] = df['anomoly_score_inverse']+1\n",
    "df['output'] = if_model.predict(df[data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply to each row\n",
    "def assign_anomaly_score(row):\n",
    "    if row['anomoly_score_inverse']<  0.3:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df['output_anomaly_score'] = df.apply(assign_anomaly_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useless Experimentation By Iftikhar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =>  \"['COUNTER_ID'] not in index\"\n",
      "Error Processing file =>  all_combined_EMA2233M10308.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uikra\\AppData\\Local\\Temp\\ipykernel_3056\\846750267.py:6: DtypeWarning:\n",
      "\n",
      "Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"data\"\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        try:\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.dropna(subset='cycle_time')\n",
    "            df = df[['shot_time','COUNTER_ID','cycle_time']]\n",
    "            data = ['cycle_time']\n",
    "            df['cycle_time'] = df['cycle_time'].apply(math.floor)\n",
    "            if_model = IsolationForest(contamination='auto',n_estimators=300,random_state=42,warm_start=True)\n",
    "            if_model.fit(df[data])\n",
    "            df['anomoly_score'] = if_model.decision_function(df[data])\n",
    "            df['anomoly_score_inverse']=if_model.score_samples(df[data])\n",
    "            # df['anomoly_score'] = df['anomoly_score']+1\n",
    "            df['anomoly_score_inverse'] = df['anomoly_score_inverse']+1\n",
    "            df['output'] = if_model.predict(df[data])\n",
    "            df.to_csv('result/'+filename)\n",
    "        except Exception as e:\n",
    "            print('Error => ',e)\n",
    "            print('Error Processing file => ',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shot_time</th>\n",
       "      <th>COUNTER_ID</th>\n",
       "      <th>output</th>\n",
       "      <th>aist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-07 23:39:24</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-07 23:39:44</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-07 23:40:04</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-07 23:40:25</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-07 23:40:45</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808867</th>\n",
       "      <td>2023-11-27 13:48:19</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808868</th>\n",
       "      <td>2023-11-27 13:48:21</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808869</th>\n",
       "      <td>2023-11-27 13:48:29</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808870</th>\n",
       "      <td>2023-11-27 13:48:30</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808871</th>\n",
       "      <td>2023-11-27 13:48:39</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808872 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  shot_time     COUNTER_ID  output  aist\n",
       "0       2022-07-07 23:39:24  EMA2227A10005       1     0\n",
       "1       2022-07-07 23:39:44  EMA2227A10005       1     0\n",
       "2       2022-07-07 23:40:04  EMA2227A10005       1     0\n",
       "3       2022-07-07 23:40:25  EMA2227A10005       1     0\n",
       "4       2022-07-07 23:40:45  EMA2227A10005       1     0\n",
       "...                     ...            ...     ...   ...\n",
       "808867  2023-11-27 13:48:19  EMA2324M10983       1     0\n",
       "808868  2023-11-27 13:48:21  EMA2324M10983       1     2\n",
       "808869  2023-11-27 13:48:29  EMA2324M10983       1     0\n",
       "808870  2023-11-27 13:48:30  EMA2324M10983       1     2\n",
       "808871  2023-11-27 13:48:39  EMA2324M10983      -1     2\n",
       "\n",
       "[808872 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concatenate_dataframes(folder):\n",
    "    # Initialize an empty list to store data frames\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterate through each file in the folder\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.csv'):\n",
    "            # Read the CSV file and append it to the list\n",
    "            df = pd.read_csv(os.path.join(folder, file))\n",
    "            dfs.append(df)\n",
    "    \n",
    "    # Concatenate all data frames in the list along the rows\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df\n",
    "\n",
    "def merge_dataframes(folder1, folder2):\n",
    "    # Concatenate data frames from each folder\n",
    "    df1 = concatenate_dataframes(folder1)\n",
    "    df2 = concatenate_dataframes(folder2)\n",
    "\n",
    "    # Merge data frames on 'shot_time' and 'COUNTER_ID'\n",
    "    merged_df = pd.merge(df1, df2, on=['shot_time', 'COUNTER_ID'], how='inner')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Replace 'folder1' and 'folder2' with the paths to your folders containing the data frames\n",
    "folder1 = 'result'\n",
    "folder2 = 'aist_result'\n",
    "\n",
    "merged_dataframe = merge_dataframes(folder1, folder2)\n",
    "merged_dataframe.rename(columns={'value2': 'aist'}, inplace=True)\n",
    "merged_dataframe = merged_dataframe[['shot_time'\t,'COUNTER_ID','output','aist']]\n",
    "merged_dataframe = merged_dataframe.dropna()\n",
    "merged_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shot_time</th>\n",
       "      <th>COUNTER_ID</th>\n",
       "      <th>output</th>\n",
       "      <th>aist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-07 23:39:24</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-07 23:39:44</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-07 23:40:04</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-07 23:40:25</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-07 23:40:45</td>\n",
       "      <td>EMA2227A10005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808867</th>\n",
       "      <td>2023-11-27 13:48:19</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808868</th>\n",
       "      <td>2023-11-27 13:48:21</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808869</th>\n",
       "      <td>2023-11-27 13:48:29</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808870</th>\n",
       "      <td>2023-11-27 13:48:30</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808871</th>\n",
       "      <td>2023-11-27 13:48:39</td>\n",
       "      <td>EMA2324M10983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808872 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  shot_time     COUNTER_ID  output  aist\n",
       "0       2022-07-07 23:39:24  EMA2227A10005       1     1\n",
       "1       2022-07-07 23:39:44  EMA2227A10005       1     1\n",
       "2       2022-07-07 23:40:04  EMA2227A10005       1     1\n",
       "3       2022-07-07 23:40:25  EMA2227A10005       1     1\n",
       "4       2022-07-07 23:40:45  EMA2227A10005       1     1\n",
       "...                     ...            ...     ...   ...\n",
       "808867  2023-11-27 13:48:19  EMA2324M10983       1     1\n",
       "808868  2023-11-27 13:48:21  EMA2324M10983       1     0\n",
       "808869  2023-11-27 13:48:29  EMA2324M10983       1     1\n",
       "808870  2023-11-27 13:48:30  EMA2324M10983       1     0\n",
       "808871  2023-11-27 13:48:39  EMA2324M10983       0     0\n",
       "\n",
       "[808872 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataframe['aist'] = merged_dataframe['aist'].apply(lambda x: 0 if x == 2 else 1)\n",
    "merged_dataframe['output'] = merged_dataframe['output'].replace({-1: 0})\n",
    "merged_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 62210 166263]\n",
      " [ 40236 540163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Ground truth\n",
    "y_true = merged_dataframe['aist']\n",
    "# Predicted labels\n",
    "y_pred = merged_dataframe['output']\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "808867    1\n",
       "808868    1\n",
       "808869    1\n",
       "808870    1\n",
       "808871    0\n",
       "Name: output, Length: 808872, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true \n",
    "\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate (FPR): 0.7277139968398891\n",
      "False Negative Rate (FNR): 0.0693247231645816\n",
      "Sensitivity: 0.9306752768354184\n",
      "Specificity: 0.2722860031601108\n",
      "Positive Predictive Value (PPV): 0.7646420148748772\n",
      "Negative Predictive Value (NPV): 0.6072467446264374\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate false positive rate (FPR)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Calculate false negative rate (FNR)\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "# Calculate sensitivity (True Positive Rate)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Calculate specificity (True Negative Rate)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate positive predictive value (PPV) or precision\n",
    "ppv = tp / (tp + fp)\n",
    "\n",
    "# Calculate negative predictive value (NPV)\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "# Print the rates\n",
    "print(\"False Positive Rate (FPR):\", fpr)\n",
    "print(\"False Negative Rate (FNR):\", fnr)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Positive Predictive Value (PPV):\", ppv)\n",
    "print(\"Negative Predictive Value (NPV):\", npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['gradient_fwd'] = df['cycle_time'].diff(1)\n",
    "# df['gradient_bck'] = df['cycle_time'].diff(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gradient_bck'] = df['cycle_time'].diff(-1) # This will fill the first value with zero, because the difference is x = x[i] - x[i+1]\n",
    "df['gradient_bck'] = df['gradient_bck'].abs()\n",
    "df['gradient_fwd'] = df['cycle_time'].diff()\n",
    "df['gradient_fwd'] = df['gradient_fwd'].abs()\n",
    "tolerance = 5\n",
    "df.loc[ (df['gradient_fwd'] >= tolerance) & (df['gradient_bck'] >= tolerance), 'output_anomaly_score'] = -1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest on Concatenated Result (without hyper parameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uikra\\AppData\\Local\\Temp\\ipykernel_22772\\3559514974.py:9: DtypeWarning:\n",
      "\n",
      "Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of files in folder\n",
    "folder_path = 'data'  # Change this to your folder path\n",
    "dfs = []  # List to hold DataFrames from each file\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):  # Assuming all files are CSVs\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append DataFrame to list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop rows with NaN values in 'cycle_time' column\n",
    "combined_df = combined_df.dropna(subset=['cycle_time'])\n",
    "combined_df.to_csv('combined_data.csv')\n",
    "# Select only 'shot_time' and 'cycle_time' columns\n",
    "combined_df = combined_df[['shot_time', 'cycle_time','COUNTER_ID']]\n",
    "\n",
    "# Apply floor function to 'cycle_time' column\n",
    "combined_df['cycle_time'] = combined_df['cycle_time'].apply(math.floor)\n",
    "\n",
    "# Define features\n",
    "data = ['cycle_time']\n",
    "\n",
    "# Initialize Isolation Forest model\n",
    "# if_model = IsolationForest(contamination='auto', random_state=42)\n",
    "if_model = IsolationForest(contamination=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Fit model\n",
    "if_model.fit(combined_df[data])\n",
    "\n",
    "# Calculate anomaly scores\n",
    "combined_df['anomoly_score'] = if_model.decision_function(combined_df[data])\n",
    "combined_df['anomoly_score_inverse'] = if_model.score_samples(combined_df[data])\n",
    "combined_df['anomoly_score_inverse'] = combined_df['anomoly_score_inverse'] + 1\n",
    "\n",
    "# Predict anomalies\n",
    "combined_df['output'] = if_model.predict(combined_df[data])\n",
    "\n",
    "# Apply the function to create the new column 'output_anomaly_score'\n",
    "combined_df['output_anomaly_score'] = combined_df.apply(assign_anomaly_score, axis=1)\n",
    "post_preprocessing = False\n",
    "if post_preprocessing == True:\n",
    "    combined_df['gradient_bck'] = combined_df['cycle_time'].diff(-1) # This will fill the first value with zero, because the difference is x = x[i] - x[i+1]\n",
    "    combined_df['gradient_bck'] = combined_df['gradient_bck'].abs()\n",
    "    combined_df['gradient_fwd'] = combined_df['cycle_time'].diff()\n",
    "    combined_df['gradient_fwd'] = combined_df['gradient_fwd'].abs()\n",
    "\n",
    "    tolerance = 5\n",
    "    combined_df.loc[ (combined_df['gradient_fwd'] >= tolerance) & (combined_df['gradient_bck'] >= tolerance), 'output'] = -1\n",
    "\n",
    "    threhold = 2\n",
    "    combined_df.loc[ (combined_df['gradient_fwd'] <= threhold) & (combined_df['gradient_bck'] <= threhold), 'output'] = 1\n",
    "\n",
    "# combined_df.loc[ (combined_df['gradient_fwd'] <= threhold) & (combined_df['gradient_bck'] <= threhold)& (combined_df['output'] == -1), 'output'] = 1\n",
    "# Save result to a new CSV file\n",
    "result_folder = 'result'  # Folder to save result\n",
    "os.makedirs(result_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "result_file_path = os.path.join(result_folder, 'combined_result_iftihar.csv')\n",
    "combined_df.to_csv(result_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest on Concatenated Result (with hyper parameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files in folder\n",
    "folder_path = 'data'  # Change this to your folder path\n",
    "dfs = []  # List to hold DataFrames from each file\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):  # Assuming all files are CSVs\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append DataFrame to list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop rows with NaN values in 'cycle_time' column\n",
    "combined_df = combined_df.dropna(subset=['cycle_time'])\n",
    "combined_df.to_csv('combined_data.csv')\n",
    "# Select only 'shot_time' and 'cycle_time' columns\n",
    "combined_df = combined_df[['shot_time', 'cycle_time','COUNTER_ID']]\n",
    "\n",
    "# Apply floor function to 'cycle_time' column\n",
    "combined_df['cycle_time'] = combined_df['cycle_time'].apply(math.floor)\n",
    "\n",
    "# Define features\n",
    "data = ['cycle_time']\n",
    "from tqdm import tqdm\n",
    "\n",
    "grid_search_dict = {\n",
    "    'cont_parm': [0.1, 0.2, 0.3, 0.4, 0.5, 'auto'],\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300, 'auto'],\n",
    "    'max_samples': [10, 20, 30, 40, 50, 60, 100, 150, 200, 'auto'],\n",
    "    'max_features': [1, 0.5, 0.8, 1, 2, 3, 'auto'],\n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False]\n",
    "}\n",
    "\n",
    "param_combinations = list(product(*grid_search_dict.values()))\n",
    "\n",
    "for comb in tqdm(param_combinations, desc=\"Generating Files\", unit=\"combination\"):\n",
    "    cont_parm, n_estimators, max_samples, max_features, bootstrap, warm_start = comb\n",
    "    filename = f\"combination_cont{cont_parm}_est{n_estimators}_samp{max_samples}_feat{max_features}_bootstrap{bootstrap}_warmstart{warm_start}\"\n",
    "\n",
    "    try:\n",
    " \n",
    "\n",
    "\n",
    "        # Initialize Isolation Forest model\n",
    "        # if_model = IsolationForest(contamination='auto', random_state=42)\n",
    "        # if_model = IsolationForest(contamination=cont_parm, random_state=42)\n",
    "\n",
    "        if_model = IsolationForest(n_estimators=n_estimators, \n",
    "                                   max_samples=max_samples, \n",
    "                                   contamination=cont_parm, \n",
    "                                   max_features=max_features,\n",
    "                                    bootstrap=bootstrap, \n",
    "                                    random_state=12, \n",
    "                                    warm_start=warm_start)\n",
    "        \n",
    "\n",
    "        # Fit model\n",
    "        if_model.fit(combined_df[data])\n",
    "\n",
    "        # Calculate anomaly scores\n",
    "        combined_df['anomoly_score'] = if_model.decision_function(combined_df[data])\n",
    "        combined_df['anomoly_score_inverse'] = if_model.score_samples(combined_df[data])\n",
    "        combined_df['anomoly_score_inverse'] = combined_df['anomoly_score_inverse'] + 1\n",
    "\n",
    "        # Predict anomalies\n",
    "        combined_df[f'output_{cont_parm}'] = if_model.predict(combined_df[data])\n",
    "\n",
    "        # Apply the function to create the new column 'output_anomaly_score'\n",
    "        combined_df[f'output_anomaly_score_{cont_parm}'] = combined_df.apply(assign_anomaly_score, axis=1)\n",
    "        # combined_df.loc[ (combined_df['gradient_fwd'] <= threhold) & (combined_df['gradient_bck'] <= threhold)& (combined_df['output'] == -1), 'output'] = 1\n",
    "        # Save result to a new CSV file\n",
    "        result_folder = 'result'  # Folder to save result\n",
    "        os.makedirs(result_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "        result_file_path = os.path.join(result_folder, f'{filename}.csv')\n",
    "        combined_df.to_csv(result_file_path, index=False)\n",
    "        # Perform garbage collection\n",
    "        gc.collect()\n",
    "        post_preprocessing = False\n",
    "        if post_preprocessing == True:\n",
    "            combined_df['gradient_bck'] = combined_df['cycle_time'].diff(-1) # This will fill the first value with zero, because the difference is x = x[i] - x[i+1]\n",
    "            combined_df['gradient_bck'] = combined_df['gradient_bck'].abs()\n",
    "            combined_df['gradient_fwd'] = combined_df['cycle_time'].diff()\n",
    "            combined_df['gradient_fwd'] = combined_df['gradient_fwd'].abs()\n",
    "\n",
    "            tolerance = 5\n",
    "            combined_df.loc[ (combined_df['gradient_fwd'] >= tolerance) & (combined_df['gradient_bck'] >= tolerance), 'output'] = -1\n",
    "\n",
    "            threhold = 2\n",
    "            combined_df.loc[ (combined_df['gradient_fwd'] <= threhold) & (combined_df['gradient_bck'] <= threhold), 'output'] = 1\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Failed filename : {filename}')\n",
    "        print('Error ->',e)\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iftikhar ki khushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_differences(df, column_name):\n",
    "    for i in range(1, 6):  # Calculate differences up to the fifth order\n",
    "        # Forward differences\n",
    "        df[f'diff_fwd_{i}'] = df[column_name].diff(periods=-i)\n",
    "        df[f'diff_fwd_{i}'] = df[f'diff_fwd_{i}'].abs().round(2)\n",
    "\n",
    "        # Backward differences\n",
    "        df[f'diff_bck_{i}'] = df[column_name].diff(periods=i)\n",
    "        df[f'diff_bck_{i}'] = df[f'diff_bck_{i}'].abs().round(2)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_forward_columns(df, n):\n",
    "    for i in range(1, n+1):\n",
    "        df[f'output_fwd_{i}'] = df['output'].shift(-i)\n",
    "    return df\n",
    "\n",
    "def create_backward_columns(df, n):\n",
    "    for i in range(1, n+1):\n",
    "        df[f'output_bck_{i}'] = df['output'].shift(i)\n",
    "    return df\n",
    "\n",
    "def create_five_shots(row):\n",
    "    fwd_columns = [f'diff_fwd_{i}' for i in range(1, 6)]\n",
    "    fwd_output_columns = [f'output_fwd_{i}' for i in range(1, 6)]\n",
    "    bck_columns = [f'diff_bck_{i}' for i in range(1, 6)]\n",
    "    bck_output_columns = [f'output_bck_{i}' for i in range(1, 6)]\n",
    "    \n",
    "    fwd_values = [(row[fwd_columns[i]], row[fwd_output_columns[i]]) for i in range(5)]\n",
    "    bck_values = [(row[bck_columns[i]], row[bck_output_columns[i]]) for i in range(5)]\n",
    "    \n",
    "    return fwd_values + bck_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/all_combined_EMA2227A10005.csv')\n",
    "df = df.dropna(subset='cycle_time')\n",
    "df = df[['shot_time','cycle_time']]\n",
    "df['output'] = -1\n",
    "df = calculate_differences(df, 'cycle_time')\n",
    "df = create_feature_column(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uikra\\AppData\\Local\\Temp\\ipykernel_22772\\3824538710.py:6: DtypeWarning:\n",
      "\n",
      "Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'data'\n",
    "dfs = [] \n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):  # Assuming all files are CSVs\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop rows with NaN values in 'cycle_time' column\n",
    "combined_df = combined_df.dropna(subset=['cycle_time'])\n",
    "\n",
    "# Select only 'shot_time' and 'cycle_time' columns\n",
    "combined_df = combined_df[['shot_time', 'cycle_time','COUNTER_ID']]\n",
    "\n",
    "# Apply floor function to 'cycle_time' column\n",
    "combined_df['cycle_time'] = combined_df['cycle_time'].apply(math.floor)\n",
    "\n",
    "# Define features\n",
    "data = ['cycle_time']\n",
    "\n",
    "# Initialize Isolation Forest model\n",
    "if_model = IsolationForest(contamination='auto', random_state=42)\n",
    "\n",
    "# Fit model\n",
    "if_model.fit(combined_df[data])\n",
    "\n",
    "# Calculate anomaly scores\n",
    "combined_df['anomoly_score'] = if_model.decision_function(combined_df[data])\n",
    "combined_df['anomoly_score_inverse'] = if_model.score_samples(combined_df[data])\n",
    "combined_df['anomoly_score_inverse'] = combined_df['anomoly_score_inverse'] + 1\n",
    "# Predict anomalies\n",
    "combined_df['output'] = if_model.predict(combined_df[data])\n",
    "# Apply the function to create the new column 'output_anomaly_score'\n",
    "combined_df['output_anomaly_score'] = combined_df.apply(assign_anomaly_score, axis=1)\n",
    "combined_df = calculate_differences(combined_df, 'cycle_time')\n",
    "tolerance = 5\n",
    "combined_df.loc[ (combined_df['diff_fwd_1'] >= tolerance) & (combined_df['diff_bck_1'] >= tolerance), 'output'] = -1\n",
    "\n",
    "threhold = 2\n",
    "combined_df.loc[ (combined_df['diff_fwd_1'] <= threhold) & (combined_df['diff_bck_1'] <= threhold), 'output'] = 1\n",
    "\n",
    "# Create forward columns\n",
    "combined_df = create_forward_columns(combined_df, 5)\n",
    "# Create backward columns\n",
    "combined_df = create_backward_columns(combined_df, 5)\n",
    "\n",
    "combined_df['five_shots'] = combined_df.apply(create_five_shots, axis=1)\n",
    "result_folder = 'result'  # Folder to save result\n",
    "os.makedirs(result_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "result_file_path = os.path.join(result_folder, 'combined_result.csv')\n",
    "combined_df.to_csv(result_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA2233M10017_model_response\n",
      "EMA2233M10024_model_response\n",
      "EMA2233M10035_model_response\n",
      "EMA2233M10100_model_response\n",
      "EMA2233M10102_model_response\n",
      "EMA2233M10103_model_response\n",
      "EMA2303M10302_model_response\n"
     ]
    }
   ],
   "source": [
    "def process_file(file_path, output_directory,name):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['shot_time'] = pd.to_datetime(data['shot_time'])\n",
    "    data = data.sort_values(by='shot_time')\n",
    "    data = data.dropna(subset=['cycle_time'])\n",
    "    # Group by COUNTER_ID\n",
    "    grouped_data = data.groupby('COUNTER_ID')\n",
    "\n",
    "    for counter_id, group_data in grouped_data:\n",
    "        # Set color for markers based on output_anomaly_score column\n",
    "        colors = ['red' if score == 2 else 'rgb(31, 119, 180)' for score in group_data['value2']]\n",
    "\n",
    "        # Assuming 'cycle_time' and 'shot_time' are columns in your DataFrame\n",
    "        hover_text = [f\"Cycle Time: {ct}<br>Shot Time: {st}\" \n",
    "                    for ct, st in zip(group_data['cycle_time'], group_data['shot_time'])]\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=group_data['shot_time'], y=group_data['cycle_time'], \n",
    "                                 mode='markers+lines', line=dict(color='darkgrey', width=1), \n",
    "                                 marker=dict(symbol='circle', size=8, color=colors),\n",
    "                                #  hoverinfo='text'))\n",
    "                                 hovertext=hover_text))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f'Cycle Time vs Measurement Date - Counter ID: {counter_id}',\n",
    "            xaxis_title='Measurement Date',\n",
    "            yaxis_title='Cycle Time (seconds)',\n",
    "            template='plotly_white',\n",
    "            plot_bgcolor='lightgrey',\n",
    "            xaxis=dict(\n",
    "                showgrid=True,\n",
    "                gridcolor='white',\n",
    "                tickfont=dict(size=14) \n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showgrid=True,\n",
    "                gridcolor='white',\n",
    "                tickfont=dict(size=14)\n",
    "            )\n",
    "        )\n",
    "        # Output file name based on counter_id\n",
    "        filename = os.path.join(output_directory, f'{name+counter_id}_ct.html')\n",
    "        fig.write_html(filename)\n",
    "\n",
    "output_directory = \"labelled_data_plot\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "input_directory = \"Labelled_Data\"\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        name =filename[:-4]\n",
    "        print(name)\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        process_file(file_path, output_directory,name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, output_directory):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['shot_time'] = pd.to_datetime(data['shot_time'])\n",
    "    data = data.dropna(subset=['cycle_time'])\n",
    "\n",
    "    # Set color for markers based on output_anomaly_score column\n",
    "    colors = ['red' if score == -1 else 'rgb(31, 119, 180)' for score in data['output']]\n",
    "\n",
    "    # Add hover text with anomoly_score_inverse\n",
    "    hover_text = [f\"Cycle Time: {ct}<br>Anomaly Score Inverse: {score_inv}\" \n",
    "                  for ct, score_inv in zip(data['cycle_time'], data['anomoly_score_inverse'])]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=data['shot_time'], y=data['cycle_time'], \n",
    "                             mode='markers+lines', line=dict(color='darkgrey', width=1), \n",
    "                             marker=dict(symbol='circle', size=8, color=colors),\n",
    "                             hoverinfo='text',\n",
    "                             hovertext=hover_text))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Cycle Time vs Measurement Date ',\n",
    "        xaxis_title='Measurement Date',\n",
    "        yaxis_title='Cycle Time (seconds)',\n",
    "        template='plotly_white',\n",
    "        plot_bgcolor='lightgrey',\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='white',\n",
    "            tickfont=dict(size=14) \n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='white',\n",
    "            tickfont=dict(size=14)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Assuming file_path and output_directory are defined\n",
    "    filename = os.path.join(output_directory, '{}_ct.html'.format(os.path.basename(file_path).split('.')[0]))\n",
    "    fig.write_html(filename)\n",
    "\n",
    "output_directory = \"ct_plots\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "input_directory = \"result\"\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        process_file(file_path, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation forest results file by file (Auto-Mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EMA2233M10295_model_response.csv complete -----------\n",
      "----------- EMA2233M10296_model_response.csv complete -----------\n",
      "----------- EMA2233M10297_model_response.csv complete -----------\n",
      "----------- EMA2233M10300_model_response.csv complete -----------\n",
      "----------- EMA2233M10302_model_response.csv complete -----------\n",
      "----------- EMA2233M10303_model_response.csv complete -----------\n",
      "----------- EMA2233M10304_model_response.csv complete -----------\n",
      "----------- EMA2233M10305_model_response.csv complete -----------\n",
      "----------- EMA2233M10308_model_response.csv complete -----------\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the files\n",
    "folder_path = 'aist_resut_ver2_electrolux/'\n",
    "result_path = 'if_results_electrolux'\n",
    "# Create a folder to store the results if it doesn't exist\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "        # Drop NaN values and select relevant columns\n",
    "        df = df.dropna(subset=['cycle_time'])\n",
    "        df = df[['shot_time','COUNTER_ID', 'cycle_time']]\n",
    "        df['cycle_time'] = df['cycle_time'].apply(math.floor)\n",
    "        \n",
    "        # Fit Isolation Forest model\n",
    "        data = ['cycle_time']\n",
    "        if_model = IsolationForest(contamination='auto', random_state=42, warm_start=True)\n",
    "        if_model.fit(df[data])\n",
    "        \n",
    "        # Calculate anomaly scores\n",
    "        df['anomoly_score'] = if_model.decision_function(df[data])\n",
    "        df['anomoly_score_inverse'] = if_model.score_samples(df[data])\n",
    "        df['anomoly_score_inverse'] = df['anomoly_score_inverse'] + 1\n",
    "        # Predict anomalies and assign anomaly scores\n",
    "        df['output'] = if_model.predict(df[data])\n",
    "        df['output'] = df['output'].apply(lambda x: 0 if x == -1 else 1)\n",
    "        df['output'] = 1 - df['output']\n",
    "\n",
    "        # Save the results in a new CSV file\n",
    "        result_filename = os.path.join(result_path, filename)\n",
    "        df.to_csv(result_filename, index=False)\n",
    "        print(f\"----------- {filename} complete -----------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Approach for finding best hyper parameters for Isolation forest\n",
    "==> It involves comparing ground truth against different results obtained, the best parameter would be the one with less false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_ground_truth(predictions, ground_truth):\n",
    "    ground_truth = ground_truth.astype(int)\n",
    "    predictions = predictions.astype(int)\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(ground_truth, predictions)\n",
    "    # Calculate false positive and false negative rates\n",
    "    false_positive_rate = conf_matrix[0, 1] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    false_negative_rate = conf_matrix[1, 0] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    return false_positive_rate,conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder path\n",
    "folder_path = \"Labelled_Data/\"\n",
    "results_df = pd.DataFrame(columns=['File', 'Best Parameters', 'Best Score'])\n",
    "# Iterate over files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        # Load data from file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        combined_df = pd.read_csv(file_path)\n",
    "\n",
    "        # Load ground truth DataFrame\n",
    "        ground_truth = pd.read_csv(file_path)  # Update with your ground truth file path\n",
    "        ground_truth = ground_truth[['shot_time', 'COUNTER_ID', 'cycle_time', 'value2']]\n",
    "        ground_truth.rename(columns={'value2': 'ground_truth'}, inplace=True)\n",
    "        ground_truth['ground_truth'] = ground_truth['ground_truth'].apply(lambda x: 0 if x == 2 else 1)\n",
    "        ground_truth['ground_truth'] = 1 - ground_truth['ground_truth'] # Inverting it for clarity 1 means anomaly and 0 means normal (1 is positive class and 0 is negative class)\n",
    "\n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 150, 200],\n",
    "            'max_samples': ['auto',0.1,0.2,0.3,0.4,0.5],\n",
    "            'contamination': ['auto', 0.1,0.2,0.3,0.4,0.5],\n",
    "            'max_features': [1.0,0.1,0.2,0.3,0.4,0.5],\n",
    "            'bootstrap': [True, False],\n",
    "            'warm_start': [True, False]\n",
    "        }\n",
    "        # Iterate over parameter grid\n",
    "        best_score = float('-inf')\n",
    "        best_params = None\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            # Create Isolation Forest model\n",
    "            if_model = IsolationForest(**params, random_state=12)\n",
    "            data = ['cycle_time']\n",
    "            # Fit model\n",
    "            if_model.fit(combined_df[data])\n",
    "\n",
    "            # Calculate anomaly scores\n",
    "            combined_df['anomaly_score'] = if_model.decision_function(combined_df[data])\n",
    "            combined_df['anomaly_score_inverse'] = if_model.score_samples(combined_df[data])\n",
    "\n",
    "            # Predict anomalies\n",
    "            combined_df[f'output_{params[\"contamination\"]}'] = if_model.predict(combined_df[data])\n",
    "            combined_df[f'output_{params[\"contamination\"]}'] = combined_df[f'output_{params[\"contamination\"]}'].apply(lambda x: 0 if x == -1 else 1)\n",
    "            combined_df[f'output_{params[\"contamination\"]}'] = 1 - combined_df[f'output_{params[\"contamination\"]}'] # Inverting it for clarity 1 means anomaly and 0 means normal (1 is positive class and 0 is negative class)\n",
    "\n",
    "            # Compare results with ground truth\n",
    "            score, cm = compare_with_ground_truth(combined_df[f'output_{params[\"contamination\"]}'], ground_truth['ground_truth'])\n",
    "\n",
    "            # Update best parameters if necessary\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "                conf_matrix = cm\n",
    "        # Store best parameters and score in DataFrame\n",
    "        results_df = results_df.append({'File': file_name, 'Best Parameters': best_params, 'Best Score': best_score}, ignore_index=True)\n",
    "        print(\"File:\", file_name)\n",
    "        print(\"Best parameters:\", best_params)\n",
    "        print(\"Best score:\", best_score)\n",
    "        print(\"Confusion Matrix:\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
